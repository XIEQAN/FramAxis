{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 基于五大道德基础理论构建语义轴",
   "id": "a07159fd84ff253e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T09:20:23.472199Z",
     "start_time": "2025-04-13T09:20:15.057970Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "from gensim.models import KeyedVectors\n",
    "import warnings\n",
    "import logging"
   ],
   "id": "3a30bacdc39cc09",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T09:22:29.391439Z",
     "start_time": "2025-04-13T09:22:29.386999Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 设置日志\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "def load_word2vec_model(model_path):\n",
    "    \"\"\"\n",
    "    加载word2vec模型\n",
    "    \n",
    "    Args:\n",
    "        model_path (str): 模型文件路径\n",
    "        \n",
    "    Returns:\n",
    "        KeyedVectors: 加载的词向量模型\n",
    "    \"\"\"\n",
    "    print(f\"正在加载词向量模型: {model_path}\")\n",
    "    try:\n",
    "        # 加载文本格式的word2vec模型\n",
    "        word_vectors = KeyedVectors.load_word2vec_format(model_path, binary=False)\n",
    "        print(f\"模型加载成功，词汇量: {len(word_vectors.key_to_index)}\")\n",
    "        return word_vectors\n",
    "    except Exception as e:\n",
    "        print(f\"模型加载失败: {str(e)}\")\n",
    "        raise"
   ],
   "id": "d93712b51214349a",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T09:22:31.353036Z",
     "start_time": "2025-04-13T09:22:31.348292Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_moral_axis(word_vectors, positive_word, negative_word):\n",
    "    \"\"\"\n",
    "    基于正向词和负向词创建道德轴向量\n",
    "    \n",
    "    Args:\n",
    "        word_vectors (KeyedVectors): 词向量模型\n",
    "        positive_word (str): 正向极词\n",
    "        negative_word (str): 负向极词\n",
    "        \n",
    "    Returns:\n",
    "        numpy.ndarray: 道德轴向量\n",
    "    \"\"\"\n",
    "    # 检查词是否在词向量模型中\n",
    "    if positive_word not in word_vectors:\n",
    "        warnings.warn(f\"警告: '{positive_word}' 不在词向量模型中\")\n",
    "        return None\n",
    "    \n",
    "    if negative_word not in word_vectors:\n",
    "        warnings.warn(f\"警告: '{negative_word}' 不在词向量模型中\")\n",
    "        return None\n",
    "   \n",
    "    # 计算向量差作为道德轴\n",
    "    axis_vector = word_vectors[positive_word] - word_vectors[negative_word]\n",
    "    return axis_vector"
   ],
   "id": "694d4be32466f846",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T09:22:37.090350Z",
     "start_time": "2025-04-13T09:22:37.086325Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def build_moral_axes(word_vectors, moral_poles):\n",
    "    \"\"\"\n",
    "    构建所有道德轴\n",
    "    \n",
    "    Args:\n",
    "        word_vectors (KeyedVectors): 词向量模型\n",
    "        moral_poles (dict): 包含道德轴及其正负极词的字典\n",
    "        \n",
    "    Returns:\n",
    "        dict: 道德轴向量字典\n",
    "    \"\"\"\n",
    "    moral_axes = {}\n",
    "    \n",
    "    for axis_name, (positive_word, negative_word) in moral_poles.items():\n",
    "        print(f\"构建 {axis_name} 轴: {positive_word} vs {negative_word}\")\n",
    "        axis_vector = create_moral_axis(word_vectors, positive_word, negative_word)\n",
    "        \n",
    "        if axis_vector is not None:\n",
    "            moral_axes[axis_name] = axis_vector\n",
    "            # 打印轴的前10维值\n",
    "            print(f\"{axis_name} 轴前10维值: {axis_vector[:10]}\")\n",
    "            print(\"-\" * 50)\n",
    "    \n",
    "    return moral_axes"
   ],
   "id": "b23568c28c22a008",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T09:22:39.176171Z",
     "start_time": "2025-04-13T09:22:39.172881Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def save_moral_axes(moral_axes, output_path):\n",
    "    \"\"\"\n",
    "    保存道德轴向量到文件\n",
    "    \n",
    "    Args:\n",
    "        moral_axes (dict): 道德轴向量字典\n",
    "        output_path (str): 输出文件路径\n",
    "    \"\"\"\n",
    "    with open(output_path, 'wb') as f:\n",
    "        pickle.dump(moral_axes, f)\n",
    "    print(f\"道德轴向量已保存至: {output_path}\")"
   ],
   "id": "1af62c70c6e5ec00",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-13T09:23:08.840926Z",
     "start_time": "2025-04-13T09:22:41.114791Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def main():\n",
    "    # 定义模型路径\n",
    "    model_path = r\"D:\\pythonProject\\C_MFD2.0_embedding\\词嵌入模型文件夹\\zhihu\\sgns.zhihu.word\"\n",
    "    \n",
    "    # 确认文件是否存在\n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"错误: 模型文件不存在 - {model_path}\")\n",
    "        return\n",
    "    \n",
    "    # 定义五大道德基础对应的极性词对\n",
    "    moral_poles = {\n",
    "        \"care\": (\"关爱\", \"伤害\"),\n",
    "        \"fairness\": (\"公平\", \"欺骗\"),\n",
    "        \"loyalty\": (\"忠诚\", \"背叛\"),\n",
    "        \"authority\": (\"服从\", \"反叛\"),\n",
    "        \"purity\": (\"纯洁\", \"污秽\")\n",
    "    }\n",
    "    \n",
    "    # 加载词向量模型\n",
    "    word_vectors = load_word2vec_model(model_path)\n",
    "    \n",
    "    # 构建道德轴\n",
    "    moral_axes = build_moral_axes(word_vectors, moral_poles)\n",
    "    \n",
    "    # 保存道德轴向量\n",
    "    output_path = \"moral_axes.pkl\"\n",
    "    save_moral_axes(moral_axes, output_path)\n",
    "    \n",
    "    # 打印缺失的词汇\n",
    "    missing_words = []\n",
    "    for axis_name, (positive_word, negative_word) in moral_poles.items():\n",
    "        if positive_word not in word_vectors:\n",
    "            missing_words.append(positive_word)\n",
    "        if negative_word not in word_vectors:\n",
    "            missing_words.append(negative_word)\n",
    "    \n",
    "    if missing_words:\n",
    "        print(f\"警告: 以下词汇不在词向量模型中: {', '.join(missing_words)}\")\n",
    "    else:\n",
    "        print(\"所有极性词都在词向量模型中，构建成功!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-13 17:22:41,118 : INFO : loading projection weights from D:\\pythonProject\\C_MFD2.0_embedding\\词嵌入模型文件夹\\zhihu\\sgns.zhihu.word\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在加载词向量模型: D:\\pythonProject\\C_MFD2.0_embedding\\词嵌入模型文件夹\\zhihu\\sgns.zhihu.word\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-13 17:23:01,419 : WARNING : duplicate word '--------------------------------------------------------------------------------------------------' in word2vec file, ignoring all but first\n",
      "2025-04-13 17:23:02,208 : WARNING : duplicate word '--------------------------------------------------------------------------------------------------' in word2vec file, ignoring all but first\n",
      "2025-04-13 17:23:03,805 : WARNING : duplicate word '--------------------------------------------------------------------------------------------------' in word2vec file, ignoring all but first\n",
      "2025-04-13 17:23:04,957 : WARNING : duplicate word '--------------------------------------------------------------------------------------------------' in word2vec file, ignoring all but first\n",
      "2025-04-13 17:23:05,702 : WARNING : duplicate word '--------------------------------------------------------------------------------------------------' in word2vec file, ignoring all but first\n",
      "2025-04-13 17:23:07,071 : WARNING : duplicate word '--------------------------------------------------------------------------------------------------' in word2vec file, ignoring all but first\n",
      "2025-04-13 17:23:07,319 : WARNING : duplicate word '--------------------------------------------------------------------------------------------------' in word2vec file, ignoring all but first\n",
      "2025-04-13 17:23:07,612 : WARNING : duplicate word '--------------------------------------------------------------------------------------------------' in word2vec file, ignoring all but first\n",
      "2025-04-13 17:23:07,654 : WARNING : duplicate word '--------------------------------------------------------------------------------------------------' in word2vec file, ignoring all but first\n",
      "2025-04-13 17:23:07,680 : WARNING : duplicate word '--------------------------------------------------------------------------------------------------' in word2vec file, ignoring all but first\n",
      "2025-04-13 17:23:07,838 : WARNING : duplicate word '--------------------------------------------------------------------------------------------------' in word2vec file, ignoring all but first\n",
      "2025-04-13 17:23:07,850 : WARNING : duplicate word '--------------------------------------------------------------------------------------------------' in word2vec file, ignoring all but first\n",
      "2025-04-13 17:23:08,090 : WARNING : duplicate word '--------------------------------------------------------------------------------------------------' in word2vec file, ignoring all but first\n",
      "2025-04-13 17:23:08,116 : WARNING : duplicate word '--------------------------------------------------------------------------------------------------' in word2vec file, ignoring all but first\n",
      "2025-04-13 17:23:08,304 : WARNING : duplicate word '--------------------------------------------------------------------------------------------------' in word2vec file, ignoring all but first\n",
      "2025-04-13 17:23:08,323 : WARNING : duplicate word '--------------------------------------------------------------------------------------------------' in word2vec file, ignoring all but first\n",
      "2025-04-13 17:23:08,327 : WARNING : duplicate word '--------------------------------------------------------------------------------------------------' in word2vec file, ignoring all but first\n",
      "2025-04-13 17:23:08,358 : WARNING : duplicate word '--------------------------------------------------------------------------------------------------' in word2vec file, ignoring all but first\n",
      "2025-04-13 17:23:08,452 : WARNING : duplicate word '--------------------------------------------------------------------------------------------------' in word2vec file, ignoring all but first\n",
      "2025-04-13 17:23:08,527 : WARNING : duplicate word '--------------------------------------------------------------------------------------------------' in word2vec file, ignoring all but first\n",
      "2025-04-13 17:23:08,574 : WARNING : duplicate word '--------------------------------------------------------------------------------------------------' in word2vec file, ignoring all but first\n",
      "2025-04-13 17:23:08,603 : WARNING : duplicate word '--------------------------------------------------------------------------------------------------' in word2vec file, ignoring all but first\n",
      "2025-04-13 17:23:08,630 : WARNING : duplicate word '--------------------------------------------------------------------------------------------------' in word2vec file, ignoring all but first\n",
      "2025-04-13 17:23:08,662 : WARNING : duplicate word '--------------------------------------------------------------------------------------------------' in word2vec file, ignoring all but first\n",
      "2025-04-13 17:23:08,681 : WARNING : duplicate word '--------------------------------------------------------------------------------------------------' in word2vec file, ignoring all but first\n",
      "2025-04-13 17:23:08,686 : WARNING : duplicate word '--------------------------------------------------------------------------------------------------' in word2vec file, ignoring all but first\n",
      "2025-04-13 17:23:08,687 : WARNING : duplicate word '--------------------------------------------------------------------------------------------------' in word2vec file, ignoring all but first\n",
      "2025-04-13 17:23:08,692 : WARNING : duplicate word '--------------------------------------------------------------------------------------------------' in word2vec file, ignoring all but first\n",
      "2025-04-13 17:23:08,702 : WARNING : duplicate word '--------------------------------------------------------------------------------------------------' in word2vec file, ignoring all but first\n",
      "2025-04-13 17:23:08,711 : WARNING : duplicate word '--------------------------------------------------------------------------------------------------' in word2vec file, ignoring all but first\n",
      "2025-04-13 17:23:08,728 : WARNING : duplicate word '--------------------------------------------------------------------------------------------------' in word2vec file, ignoring all but first\n",
      "2025-04-13 17:23:08,729 : WARNING : duplicate word '--------------------------------------------------------------------------------------------------' in word2vec file, ignoring all but first\n",
      "2025-04-13 17:23:08,735 : WARNING : duplicate word '--------------------------------------------------------------------------------------------------' in word2vec file, ignoring all but first\n",
      "2025-04-13 17:23:08,741 : WARNING : duplicate word '--------------------------------------------------------------------------------------------------' in word2vec file, ignoring all but first\n",
      "2025-04-13 17:23:08,752 : WARNING : duplicate word '--------------------------------------------------------------------------------------------------' in word2vec file, ignoring all but first\n",
      "2025-04-13 17:23:08,754 : WARNING : duplicate word '--------------------------------------------------------------------------------------------------' in word2vec file, ignoring all but first\n",
      "2025-04-13 17:23:08,757 : WARNING : duplicate word '--------------------------------------------------------------------------------------------------' in word2vec file, ignoring all but first\n",
      "2025-04-13 17:23:08,758 : WARNING : duplicate word '--------------------------------------------------------------------------------------------------' in word2vec file, ignoring all but first\n",
      "2025-04-13 17:23:08,764 : WARNING : duplicate word '--------------------------------------------------------------------------------------------------' in word2vec file, ignoring all but first\n",
      "2025-04-13 17:23:08,768 : WARNING : duplicate word '--------------------------------------------------------------------------------------------------' in word2vec file, ignoring all but first\n",
      "2025-04-13 17:23:08,774 : WARNING : duplicate word '--------------------------------------------------------------------------------------------------' in word2vec file, ignoring all but first\n",
      "2025-04-13 17:23:08,776 : WARNING : duplicate word '--------------------------------------------------------------------------------------------------' in word2vec file, ignoring all but first\n",
      "2025-04-13 17:23:08,779 : WARNING : duplicate word '..................................................................................................' in word2vec file, ignoring all but first\n",
      "2025-04-13 17:23:08,781 : WARNING : duplicate word '..................................................................................................' in word2vec file, ignoring all but first\n",
      "2025-04-13 17:23:08,782 : WARNING : duplicate word '--------------------------------------------------------------------------------------------------' in word2vec file, ignoring all but first\n",
      "2025-04-13 17:23:08,785 : WARNING : duplicate word '--------------------------------------------------------------------------------------------------' in word2vec file, ignoring all but first\n",
      "2025-04-13 17:23:08,786 : WARNING : duplicate word '--------------------------------------------------------------------------------------------------' in word2vec file, ignoring all but first\n",
      "2025-04-13 17:23:08,787 : WARNING : duplicate word '--------------------------------------------------------------------------------------------------' in word2vec file, ignoring all but first\n",
      "2025-04-13 17:23:08,788 : WARNING : duplicate word '..................................................................................................' in word2vec file, ignoring all but first\n",
      "2025-04-13 17:23:08,790 : WARNING : duplicate word '..................................................................................................' in word2vec file, ignoring all but first\n",
      "2025-04-13 17:23:08,792 : WARNING : duplicate word '--------------------------------------------------------------------------------------------------' in word2vec file, ignoring all but first\n",
      "2025-04-13 17:23:08,795 : WARNING : duplicate word '..................................................................................................' in word2vec file, ignoring all but first\n",
      "2025-04-13 17:23:08,796 : WARNING : duplicate word '--------------------------------------------------------------------------------------------------' in word2vec file, ignoring all but first\n",
      "2025-04-13 17:23:08,798 : INFO : KeyedVectors lifecycle event {'msg': 'loaded (259922, 300) matrix of type float32 from D:\\\\pythonProject\\\\C_MFD2.0_embedding\\\\词嵌入模型文件夹\\\\zhihu\\\\sgns.zhihu.word', 'binary': False, 'encoding': 'utf8', 'datetime': '2025-04-13T17:23:08.798791', 'gensim': '4.3.3', 'python': '3.11.11 | packaged by conda-forge | (main, Mar  3 2025, 20:29:43) [MSC v.1943 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'load_word2vec_format'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型加载成功，词汇量: 259869\n",
      "构建 care 轴: 关爱 vs 伤害\n",
      "care 轴前10维值: [ 0.19804299  0.170026    0.195031    0.24005601  0.219791   -0.61237895\n",
      "  0.07190299 -0.3345     -0.17207399 -0.16585898]\n",
      "--------------------------------------------------\n",
      "构建 fairness 轴: 公平 vs 欺骗\n",
      "fairness 轴前10维值: [ 0.156525   -0.549209    0.554018    0.181344   -0.214347   -0.163257\n",
      "  0.20169699  0.15173802 -0.383707   -0.682281  ]\n",
      "--------------------------------------------------\n",
      "构建 loyalty 轴: 忠诚 vs 背叛\n",
      "loyalty 轴前10维值: [-0.34174198  0.408172    0.168324    0.256419   -0.400453    0.13650301\n",
      "  0.691694   -0.065331    0.408887   -0.438583  ]\n",
      "--------------------------------------------------\n",
      "构建 authority 轴: 服从 vs 反叛\n",
      "authority 轴前10维值: [-0.061417   -0.010115   -0.020205   -0.007423    0.20648101 -0.30812898\n",
      " -0.160135    0.73769796  0.509778   -0.3782    ]\n",
      "--------------------------------------------------\n",
      "构建 purity 轴: 纯洁 vs 污秽\n",
      "purity 轴前10维值: [-0.344228    0.185601   -0.63567     0.157436   -0.586316   -0.358316\n",
      " -0.144219   -0.21457699 -0.23995697 -0.672374  ]\n",
      "--------------------------------------------------\n",
      "道德轴向量已保存至: moral_axes.pkl\n",
      "所有极性词都在词向量模型中，构建成功!\n"
     ]
    }
   ],
   "execution_count": 8
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
